#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright 2019 The Chromium OS Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""Do all the things!"""

from __future__ import print_function

import fnmatch
import glob
import logging
import os
import shutil
import sys

import kokoro
import libdot


# Where kokoro expects files to end up.  Anything put in this dir will be
# uploaded & archived, while everything else will be discarded.
ARTIFACTS_DIR = os.path.join(kokoro.LIBAPPS_DIR, 'artifacts')

# Where we drop all our comment files for passing back to gerrit.
# Kokoro can handle more than one file, but they must all be named the same
# "gerrit_comments.json".  So we have to namespace the files under dirs.
# We'll use a convention like gerrit_comments/$PKG/$TOOL/.
GERRIT_COMMENTS_NAME = 'gerrit_comments.json'
GERRIT_COMMENTS_DIR = os.path.join(ARTIFACTS_DIR, 'gerrit_comments')


def is_presubmit():
    """Whether we're testing a pending CL."""
    # This env var is passed down by kokoro.
    return bool(os.environ.get('KOKORO_GERRIT_REVISION'))


def should_build_plugin():
    """Whether we should build the ssh_client plugin code.

    Building this native code with the nacl toolchain dominates our build times
    (usually ~75% of the entire build).  Lets skip it if we don't think any of
    changes are relevant.
    """
    logging.info('Detecting whether to build plugin')

    # Release builders always build the plugin.
    if not is_presubmit():
        logging.info('Release builder: always building the plugin!')
        return True

    check_paths = (
        # The CI itself.
        'kokoro/*',
        # Utility libraries.
        'libdot/bin/*',
        # The plugin code itself.
        'ssh_client/*',
    )
    result = libdot.run(['git', 'show', '--format=', '--name-only',
                         os.environ['KOKORO_GERRIT_REVISION']],
                        capture_output=True, cwd=kokoro.LIBAPPS_DIR)
    relevant_paths = list(
        x for x in result.stdout.decode('utf-8').splitlines()
        if any(fnmatch.fnmatch(x, check) for check in check_paths))
    if relevant_paths:
        logging.info('Presubmit: some files might affect the plugin:\n%s',
                     '\n'.join(relevant_paths))
    else:
        logging.info('Presubmit: no files affect the plugin; skipping')
    return bool(relevant_paths)


def build_archive():
    """Move compiled files to artifacts output tree."""
    # Unpack the nassh extensions so they can be packaged & signed.
    nassh_dir = os.path.join(kokoro.LIBAPPS_DIR, 'nassh')
    dist_dir = os.path.join(nassh_dir, 'dist')
    for archive in glob.glob(os.path.join(dist_dir, '*.zip')):
        # The archives look like:
        #   SecureShellApp-0.20.zip
        #   SecureShellApp-dev-0.20.7220.2157.zip
        # We want to output dirs like:
        #   SecureShellApp/
        #   SecureShellApp-dev/
        output = os.path.basename(archive).rsplit('-', 1)[0]
        libdot.run(['unzip', archive, '-d',
                    os.path.join(ARTIFACTS_DIR, output)])

    # Copy over the nacl ssh build with debug info.
    if should_build_plugin():
        ssh_client_dir = os.path.join(kokoro.LIBAPPS_DIR, 'ssh_client')
        os.rename(os.path.join(ssh_client_dir, 'output', 'release.tar.xz'),
                  os.path.join(ARTIFACTS_DIR, 'ssh_client-release.tar.xz'))


def build():
    """Build the various components."""
    if should_build_plugin():
        # Build the ssh client code.
        ssh_client_dir = os.path.join(kokoro.LIBAPPS_DIR, 'ssh_client')
        libdot.run(['./build.sh'], cwd=ssh_client_dir)
        # Copy output files.
        libdot.run(['cp', '-r', './ssh_client/output/plugin/', './nassh/'],
                   cwd=kokoro.LIBAPPS_DIR)

    # Build the nassh program.
    nassh_dir = os.path.join(kokoro.LIBAPPS_DIR, 'nassh')
    dist_dir = os.path.join(nassh_dir, 'dist')
    shutil.rmtree(dist_dir, ignore_errors=True)
    libdot.run(['./bin/mkdist'], cwd=nassh_dir)

    build_archive()


def _run_linter(cmd, cwd):
    """Run the linter taking into account presubmit bot state."""
    result = libdot.run(cmd, check=False, cwd=cwd)
    if result.returncode:
        msg = '%s linter exited %i' % (cmd[0], result.returncode)
        if is_presubmit():
            logging.error(msg)
            return False
        else:
            logging.warning('%s; ignoring for release builds', msg)
    return True


def test_jslint():
    """Lint all our JS files."""
    ret = []
    for pkg in ('libdot', 'hterm', 'nassh', 'terminal'):
        pkg_dir = os.path.join(kokoro.LIBAPPS_DIR, pkg)
        cmd = [
            './bin/lint',
            '--gerrit-comments-file',
            os.path.join(GERRIT_COMMENTS_DIR, pkg, '%(tool)',
                         GERRIT_COMMENTS_NAME),
        ]
        if not _run_linter(cmd, pkg_dir):
            ret.append(('jslint', pkg))
    return ret


def test_pylint():
    """Run pylint over all the Python files in the tree."""
    logging.info('Linting all Python files')

    # Log the linter version since we pull it from the container.
    pylint_libdot = os.path.join(kokoro.LIBAPPS_DIR, 'libdot', 'bin', 'pylint')
    libdot.run([pylint_libdot, '--version'])

    def find_pyfiles(pkg, topdir):
        """Walk |topdir| and find all Python files under it."""
        for root, dirs, files in os.walk(topdir):
            # TODO(vapier): Find a better way to handle this.  We run tests
            # after building so ssh_client/output/ is full of upstream sources.
            # We can't use `git ls-tree` as .git/ in repo checkouts isn't fully
            # mounted in the container.
            if pkg == 'ssh_client' and 'output' in dirs:
                dirs.remove('output')

            # TODO(vapier): Figure out why pylint hates us.  Running in the
            # container on these modules fails with "internal errors:
            # maximum recursion depth exceeded.".
            if pkg == 'libdot' and root == os.path.join(topdir, 'bin'):
                files.remove('node')
            elif pkg == 'ssh_client' and root == os.path.join(topdir, 'bin'):
                files.remove('ssh_client.py')

            for path in files:
                full_path = os.path.join(root, path)

                if os.path.islink(full_path):
                    # Ignore symlinks.
                    continue
                elif path.endswith('.py'):
                    # Add all .py files as they should only be Python.
                    yield os.path.relpath(full_path, pkg_dir)
                elif os.access(full_path, os.X_OK):
                    # Add executable programs with python shebangs.
                    with open(full_path, 'rb') as fp:
                        shebang = fp.readline()
                        if b'python' in shebang:
                            yield os.path.relpath(full_path, pkg_dir)

    # Lint the main dirs with the common pylint.
    ret = []
    for pkg in ('kokoro', 'libdot', 'hterm', 'nassh', 'ssh_client', 'terminal'):
        pkg_dir = os.path.join(kokoro.LIBAPPS_DIR, pkg)

        # See if the project has a custom linter.
        pylint = os.path.join(pkg_dir, 'bin', 'pylint')
        if not os.path.exists(pylint):
            # Use the common one.
            pylint = pylint_libdot

        cmd = [
            pylint,
            '--gerrit-comments-file',
            os.path.join(GERRIT_COMMENTS_DIR, pkg, '%(tool)',
                         GERRIT_COMMENTS_NAME),
        ]

        pyfiles = list(find_pyfiles(pkg, pkg_dir))
        if not _run_linter(cmd + pyfiles, pkg_dir):
            ret.append(('pylint', pkg))

    return ret


def test_unittests():
    """Run all the unittests."""
    ret = []
    for pkg in ('libdot', 'hterm', 'nassh', 'terminal'):
        pkg_dir = os.path.join(kokoro.LIBAPPS_DIR, pkg)
        if os.path.exists(os.path.join(pkg_dir, 'package.json')):
            cmd = ['npm', 'test', '--', '--no-sandbox']
        else:
            cmd = ['./bin/load_tests', '--no-sandbox']
        result = libdot.run(cmd, check=False, cwd=pkg_dir)
        if result.returncode:
            logging.error('%s test suite exited %i', pkg, result.returncode)
            ret.append(('unittests', pkg))
    return ret


def test():
    """Test the various components."""
    # Run all the tests before aborting.
    failures = test_jslint() + test_pylint() + test_unittests()
    if failures:
        logging.error('Some tests failed!  See above for details.')
        for (step, pkg) in failures:
            logging.error('  %s failed %s phase.', pkg, step)
        sys.exit(1)


def clean():
    """Clean up various compiled objects.

    When kokoro is done (pass or fail), it archives the tree via rsync.
    Remove all the compiled objects since we don't need them.
    """
    ssh_client_dir = os.path.join(kokoro.LIBAPPS_DIR, 'ssh_client')
    shutil.rmtree(os.path.join(ssh_client_dir, 'output'), ignore_errors=True)

    shutil.rmtree(libdot.node.NODE_MODULES_DIR, ignore_errors=True)

    # Sync uid/gid settings in the output artifacts.  The docker container
    # runs all code as root, but the accounts outside won't be that.  Look
    # at the source tree created outside the container for the right values.
    st = os.stat(kokoro.LIBAPPS_DIR)
    uid = st.st_uid
    gid = st.st_gid
    if uid != os.getuid():
        def chown(path):
            """Helper to chown |path| to |uid| & |gid|."""
            if os.path.islink(path):
                return
            try:
                os.chown(path, uid, gid)
            except OSError as e:
                logging.warning('Unable to chown(%s, %s, %s): %s',
                                path, uid, gid, e)

        logging.info('Changing ownership of artifacts dir to %i:%i', uid, gid)
        chown(ARTIFACTS_DIR)
        for root, dirs, files in os.walk(ARTIFACTS_DIR):
            for d in dirs:
                chown(os.path.join(root, d))
            for f in files:
                chown(os.path.join(root, f))


def setup():
    """Set up the overall state before we build/test."""
    # Log some system state so we can see current CI/container state.
    libdot.run(['uname', '-a'])
    libdot.run(['cat', '/etc/os-release'], check=False)

    # Initialize the artifacts output.
    logging.info('Setting up artifacts output %s', ARTIFACTS_DIR)
    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)
    os.makedirs(ARTIFACTS_DIR)

    # Create the dropbox for gerrit comments.
    os.makedirs(GERRIT_COMMENTS_DIR)
    # Always create a stub comments file.  The kokoro docs don't say this is
    # required, but other users report it doesn't post updates back to Gerrit
    # unless it exists, and we're seeing that same behavior.
    # http://g/kokoro-users/coBW2tNu46g/W8PozUUpAQAJ
    stub = os.path.join(GERRIT_COMMENTS_DIR, GERRIT_COMMENTS_NAME)
    with open(stub, 'w') as fp:
        fp.write('[]')


def get_parser():
    """Get a command line parser."""
    parser = libdot.ArgumentParser(description=__doc__)
    parser.add_argument('--skip-clean', dest='clean',
                        action='store_false', default=True,
                        help='Clean up compiled object dirs.')
    return parser


def main(argv):
    """The main func!"""
    parser = get_parser()
    opts = parser.parse_args(argv)
    libdot.node_and_npm_setup()

    setup()
    try:
        build()
        test()
        logging.info('All builds & tests passed!')
    finally:
        if opts.clean:
            clean()

if __name__ == '__main__':
    sys.exit(main(sys.argv[1:]))
